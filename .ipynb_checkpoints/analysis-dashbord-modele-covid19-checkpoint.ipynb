{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source des donnees et bibliographie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/\n",
    "\n",
    "https://machinelearningmastery.com/grid-search-arima-hyperparameters-with-python/\n",
    "\n",
    "https://raw.githubusercontent.com/maelfabien/\n",
    "\n",
    "https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/\n",
    "\n",
    "https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/\n",
    "https://www.cairn.info/revue-de-l-ofce-2003-3-page-203.htm\n",
    "\n",
    "https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/\n",
    "\n",
    "https://www.statsmodels.org/stable/statespace.html\n",
    "\n",
    "https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/\n",
    "\n",
    "https://www.statsmodels.org/dev/examples/notebooks/generated/statespace_sarimax_stata.html\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
    "\n",
    "https://www.lewuathe.com/covid-19-dynamics-with-sir-model.html\n",
    "\n",
    "https://towardsdatascience.com/a-bayesian-approach-to-time-series-forecasting-d97dd4168cb7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import random\n",
    "import math\n",
    "from scipy.stats import expon\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import datetime\n",
    "import operator \n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "#from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing  data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous travaillons avec les donnees publiees sur le site du ministere de la sante du senegal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"https://raw.githubusercontent.com/maelfabien/COVID-19-Senegal/master/COVID_Dakar.csv\",sep=\";\" )\n",
    "#df.tail()\n",
    "df = pd.read_csv(\"COVID_Senegal.csv\",sep=\";\" )\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les donnees sont dispatchees dans trois categories : cas confirmes, cas deces et cas gueri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_df = df[df['Positif']==1]\n",
    "confirmed = confirmed_df[['Date', 'Positif']]\n",
    "confirmed_cases= confirmed[['Date', 'Positif']].groupby(\"Date\").sum()\n",
    "\n",
    "deaths_df = df[df['Décédé']==1]\n",
    "deaths = deaths_df[['Date', 'Décédé']]\n",
    "deaths_cases= deaths[['Date', 'Décédé']].groupby(\"Date\").sum()\n",
    "\n",
    "recoveries_df = df[df['Guéri']==1]\n",
    "recoveries = recoveries_df[['Date', 'Guéri']]\n",
    "recoveries_cases= recoveries[['Date', 'Guéri']].groupby(\"Date\").sum()\n",
    "\n",
    "\n",
    "negatif_df = df[df['Negatif']==1  ]\n",
    "negatif = negatif_df[['Date', 'Negatif']]\n",
    "negatif_cases=negatif[['Date', 'Negatif']].groupby(\"Date\").sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptif Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la premiere partie, nous regardons la relation entre le nombre de tests effectues par jour et le nombre \n",
    "de cas positifs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.DataFrame(confirmed_cases)\n",
    "test2 = pd.DataFrame(negatif_cases)\n",
    "total_cases = pd.concat([test1, test2], axis=1)\n",
    "total_cases = total_cases.fillna(0)\n",
    "total_cases['Negatif']\n",
    "total = total_cases['Positif'] + total_cases['Negatif']\n",
    "#prop = total_cases['Positif']/ total\n",
    "#total_cases\n",
    "#total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(total)\n",
    "plt.plot(total_cases['Positif'])\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette figure resume le nombre de tests et le nombre de cas confirmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "# width of the bars\n",
    "barWidth = 0.3\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(total_cases['Positif']))\n",
    "r2 = [x + barWidth for x in r1]\n",
    " \n",
    "# Create blue bars\n",
    "plt.bar(r1,total_cases['Positif'], width = barWidth, color = 'red', edgecolor = 'black', capsize=7, label=' cas positif')\n",
    " \n",
    "# Create cyan bars\n",
    "plt.bar(r2, total, width = barWidth, color = 'blue', edgecolor = 'black', capsize=7, label='Nbr de Tests')\n",
    " \n",
    "# general layout\n",
    "#plt.xticks([r + barWidth for r in range(len(bars1))], ['cond_A', 'cond_B', 'cond_C'])\n",
    "plt.ylabel('Nombres')\n",
    "plt.legend()\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde le nombre cumulatif des cas confirmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "# width of the bars\n",
    "barWidth = 0.3\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(total_cases['Positif']))\n",
    "r2 = [x + barWidth for x in r1]\n",
    " \n",
    "# Create blue bars\n",
    "plt.bar(r1,total_cases['Positif'].cumsum(), width = barWidth, color = 'red', edgecolor = 'black', capsize=7, label=' cas positif')\n",
    " \n",
    "# Create cyan bars\n",
    "#plt.bar(r2, total.cumsum(), width = barWidth, color = 'blue', edgecolor = 'black', capsize=7, label='Nbr de Tests')\n",
    " \n",
    "# general layout\n",
    "#plt.xticks([r + barWidth for r in range(len(bars1))], ['cond_A', 'cond_B', 'cond_C'])\n",
    "plt.ylabel('Nombres')\n",
    "plt.legend()\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax=plt.subplots()\n",
    "#echantillon de variables exponentielles de parametre 2:\n",
    "X=expon.rvs(scale=0.5, size=10000)\n",
    "#histogramme associe:\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(total_cases['Positif']))\n",
    "r2 = [x + barWidth for x in r1]\n",
    " \n",
    "# Create blue bars\n",
    "#plt.bar(r1,total_cases['Positif'].cumsum(), width = barWidth, color = 'red', edgecolor = 'black', capsize=7, label=' cas positif')\n",
    " \n",
    "#ax.hist(X,bins=30, density=True, label=\"histogramme\")\n",
    "\n",
    "fig.suptitle(\"Exponentielle de paramètre 2\")\n",
    "#densité de la loi associée:\n",
    "x=np.arange(0,max(total_cases['Positif'].cumsum()), 5)\n",
    "ax.plot(x,expon.pdf(x, scale=0.5), label=\"densité\") \n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_cases['Positif'].cumsum(), expon.pdf(total_cases['Positif'].cumsum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(total_cases['Positif'].cumsum(),fit =expon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "# width of the bars\n",
    "barWidth = 0.3\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(total_cases['Positif']))\n",
    "r2 = [x + barWidth for x in r1]\n",
    " \n",
    "# Create blue bars\n",
    "plt.bar(r1,total_cases['Positif'].cumsum(), width = barWidth, color = 'red', edgecolor = 'black', capsize=7, label=' cas positif')\n",
    " \n",
    "# Create cyan bars\n",
    "plt.bar(r2, total.cumsum(), width = barWidth, color = 'blue', edgecolor = 'black', capsize=7, label='Nbr de Tests')\n",
    " \n",
    "# general layout\n",
    "#plt.xticks([r + barWidth for r in range(len(bars1))], ['cond_A', 'cond_B', 'cond_C'])\n",
    "plt.ylabel('Nombres')\n",
    "plt.legend()\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "# width of the bars\n",
    "barWidth = 0.3\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(total_cases['Positif']))\n",
    "r2 = [x + barWidth for x in r1]\n",
    " \n",
    "# Create blue bars\n",
    "plt.bar(r1,total_cases['Positif'].cumsum(), width = barWidth, color = 'red', edgecolor = 'black', capsize=7, label=' cas positif')\n",
    " \n",
    "# Create cyan bars\n",
    "plt.bar(r2, total.cumsum(), width = barWidth, color = 'blue', edgecolor = 'black', capsize=7, label='Nbr de Tests')\n",
    " \n",
    "# general layout\n",
    "#plt.xticks([r + barWidth for r in range(len(bars1))], ['cond_A', 'cond_B', 'cond_C'])\n",
    "plt.ylabel('Nombres')\n",
    "plt.legend()\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,5))\n",
    "plt.plot(confirmed_cases, color = 'red', label = 'cas positif')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylabel('Nombres')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,5))\n",
    "plt.plot(np.log(confirmed_cases), color = 'red')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_since = np.array([i for i in range(len(confirmed_cases))]).reshape(-1, 1)\n",
    "senegal_cases = np.array(confirmed_cases).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_since_cum = np.array([i for i in range(len(confirmed_cases.cumsum()))]).reshape(-1, 1)\n",
    "senegal_cases_cum = np.array(confirmed_cases.cumsum()).reshape(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "days_in_future = n\n",
    "future_forcast = np.array([i for i in range(len(confirmed_cases)+days_in_future)]).reshape(-1, 1)\n",
    "adjusted_dates = future_forcast[:-n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '03/03/2020'\n",
    "start_date = datetime.datetime.strptime(start, '%d/%m/%Y')\n",
    "future_forcast_dates = []\n",
    "for i in range(len(future_forcast)):\n",
    "    future_forcast_dates.append((start_date + datetime.timedelta(days=i)).strftime('%d/%m/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_confirmed, X_test_confirmed, y_train_confirmed, y_test_confirmed = train_test_split(days_since, senegal_cases, test_size=0.25, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_confirmed = svm_search.best_estimator_\n",
    "svm_confirmed = SVR(shrinking=True, kernel='poly',gamma=0.01, epsilon=1,degree=5, C=0.1)\n",
    "svm_confirmed.fit(X_train_confirmed, y_train_confirmed)\n",
    "svm_pred2 = svm_confirmed.predict(X_test_confirmed)\n",
    "svm_pred2\n",
    "svm_pred = svm_confirmed.predict(future_forcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = confirmed_cases.iloc[14:19]\n",
    "test.reset_index(level=0, inplace=True)\n",
    "test['Date']\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(test['Date'],np.round(svm_pred2), color = 'blue', label = 'predictions')\n",
    "plt.plot(test['Date'] ,y_test_confirmed, color = 'red', label = 'real')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(future_forcast_dates,svm_pred, color = 'blue', label = 'predictions')\n",
    "#plt.plot(test['Date'] ,y_test_confirmed, color = 'red', label = 'real')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future predictions using Linear Regression \n",
    "print('Support Vectors Machines  future predictions:')\n",
    "set(zip(future_forcast_dates[-11:], np.round(svm_pred[-11:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian ridge \n",
    "tol = [1e-4, 1e-3, 1e-2]\n",
    "alpha_1 = [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "alpha_2 = [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "lambda_1 = [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "lambda_2 = [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "\n",
    "bayesian_grid = {'tol': tol, 'alpha_1': alpha_1, 'alpha_2' : alpha_2, 'lambda_1': lambda_1, 'lambda_2' : lambda_2}\n",
    "\n",
    "bayesian = BayesianRidge(fit_intercept=False, normalize=True)\n",
    "bayesian_search = RandomizedSearchCV(bayesian, bayesian_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=40, verbose=1)\n",
    "bayesian_search.fit(X_train_confirmed, y_train_confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_confirmed = bayesian_search.best_estimator_\n",
    "test_bayesian_pred = bayesian_confirmed.predict(X_test_confirmed)\n",
    "bayesian_pred = bayesian_confirmed.predict(future_forcast)\n",
    "print('MAE:', mean_absolute_error(test_bayesian_pred, y_test_confirmed))\n",
    "print('MSE:',mean_squared_error(test_bayesian_pred, y_test_confirmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test = confirmed_cases.iloc[14:19]\n",
    "#test.reset_index(level=0, inplace=True)\n",
    "test['Date']\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(test['Date'],np.round(test_bayesian_pred), color = 'blue', label = 'predictions')\n",
    "plt.plot(test['Date'] ,y_test_confirmed, color = 'red', label = 'real')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "plt.plot(adjusted_dates, senegal_cases)\n",
    "plt.title('# of Coronavirus Cases Over Time', size=30)\n",
    "plt.xlabel('Days Since 03/03/2020', size=30)\n",
    "plt.ylabel('# of Cases', size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "plt.plot(adjusted_dates, senegal_cases)\n",
    "plt.plot(future_forcast, bayesian_pred, linestyle='dashed', color='green')\n",
    "plt.title('# of Coronavirus Cases Over Time', size=30)\n",
    "plt.xlabel('Time', size=30)\n",
    "plt.ylabel('# of Cases', size=30)\n",
    "plt.legend(['Confirmed Cases', 'Bayesian Ridge Regression Predictions'], prop={'size': 20})\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future predictions using Linear Regression \n",
    "print('Ridge regression future predictions:')\n",
    "set(zip(future_forcast_dates[-10:], np.round(bayesian_pred[-10:]) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporel Series Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = confirmed_cases\n",
    "size = int(len(X) * 0.66)\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "history = [x for x in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "pyplot.plot(X)\n",
    "pyplot.xticks(rotation = 90)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = confirmed_cases.values\n",
    "#Y = confirmed_cases\n",
    "\n",
    "\n",
    "train_size = int(len(Y) * 0.66)\n",
    "train, test = Y[0:train_size], Y[train_size:len(Y)]\n",
    "print('Observations: %d' % (len(Y)))\n",
    "print('Training Observations: %d' % (len(train)))\n",
    "print('Testing Observations: %d' % (len(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "pyplot.plot(train)\n",
    "pyplot.xticks(rotation = 90)\n",
    "pyplot.plot([None for i in train] + [x for x in test])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "autocorrelation_plot(X)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model = ARIMA(X, order=(5,1,0))\n",
    "model_fit = model.fit(disp=0)\n",
    "print(model_fit.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residual errors\n",
    "residuals = DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvalues = confirmed_cases.values\n",
    "size = int(len(Xvalues) * 0.66)\n",
    "train, test = Xvalues[0:size], Xvalues[size:len(Xvalues)]\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "\tmodel = ARIMA(history, order=(3,1,0))\n",
    "\tmodel_fit = model.fit(disp=0)\n",
    "\toutput = model_fit.forecast()\n",
    "\tyhat = output[0]\n",
    "\tpredictions.append(yhat)\n",
    "\tobs = test[t]\n",
    "\thistory.append(obs)\n",
    "\tprint('predicted=%f, expected=%f' % (yhat, obs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = mean_squared_error(test, predictions)\n",
    "print('Test MSE: %.3f' % error)\n",
    "# plot\n",
    "pyplot.plot(test)\n",
    "pyplot.plot(predictions, color='red')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose best parameters models ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "\tdataset = dataset.astype('float32')\n",
    "\tbest_score, best_cfg = float(\"inf\"), None\n",
    "\tfor p in p_values:\n",
    "\t\tfor d in d_values:\n",
    "\t\t\tfor q in q_values:\n",
    "\t\t\t\torder = (p,d,q)\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tmse = evaluate_arima_model(dataset, order)\n",
    "\t\t\t\t\tif mse < best_score:\n",
    "\t\t\t\t\t\tbest_score, best_cfg = mse, order\n",
    "\t\t\t\t\tprint('ARIMA%s MSE=%.3f' % (order,mse))\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tcontinue\n",
    "\tprint('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# evaluate parameters\n",
    "p_values = [0, 1, 2, 4, 6, 8, 10]\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(X.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "\t# prepare training dataset\n",
    "\ttrain_size = int(len(X) * 0.66)\n",
    "\ttrain, test = X[0:train_size], X[train_size:]\n",
    "\thistory = [x for x in train]\n",
    "\t# make predictions\n",
    "\tpredictions = list()\n",
    "\tfor t in range(len(test)):\n",
    "\t\tmodel = ARIMA(history, order=arima_order)\n",
    "\t\tmodel_fit = model.fit(disp=0)\n",
    "\t\tyhat = model_fit.forecast()[0]\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\thistory.append(test[t])\n",
    "\t# calculate out of sample error\n",
    "\terror = mean_squared_error(test, predictions)\n",
    "\treturn error\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "\n",
    "# evaluate parameters\n",
    "p_values = [0, 1, 2, 4]\n",
    "d_values = range(0, 2)\n",
    "q_values = range(0, 2)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(X.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvalues = confirmed_cases.values\n",
    "size = int(len(Xvalues) * 0.66)\n",
    "train, test = Xvalues[0:size], Xvalues[size:len(Xvalues)]\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "\tmodel = ARIMA(history, order=(0,1,1))\n",
    "\tmodel_fit = model.fit(disp=0)\n",
    "\toutput = model_fit.forecast()\n",
    "\tyhat = output[0]\n",
    "\tpredictions.append(yhat)\n",
    "\tobs = test[t]\n",
    "\thistory.append(obs)\n",
    "\tprint('predicted=%f, expected=%f' % (yhat, obs))\n",
    "error = mean_squared_error(test, predictions)\n",
    "print('Test MSE: %.3f' % error)\n",
    "# plot\n",
    "pyplot.plot(test)\n",
    "pyplot.plot(predictions, color='red')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "This cheat sheet demonstrates 11 different classical time series forecasting methods; they are:\n",
    "\n",
    "Autoregression (AR)\n",
    "Moving Average (MA)\n",
    "Autoregressive Moving Average (ARMA)\n",
    "Autoregressive Integrated Moving Average (ARIMA)\n",
    "Seasonal Autoregressive Integrated Moving-Average (SARIMA)\n",
    "Seasonal Autoregressive Integrated Moving-Average with Exogenous Regressors (SARIMAX)\n",
    "Vector Autoregression (VAR)\n",
    "Vector Autoregression Moving-Average (VARMA)\n",
    "Vector Autoregression Moving-Average with Exogenous Regressors (VARMAX)\n",
    "Simple Exponential Smoothing (SES)\n",
    "Holt Winter’s Exponential Smoothing (HWES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregression (AR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode d'autorégression (AR) modélise la prochaine étape de la séquence en fonction linéaire des observations aux pas de temps précédents.\n",
    "La notation du modèle implique de spécifier l'ordre du modèle p comme paramètre de la fonction AR, par ex. AR (p). \n",
    "Par exemple, AR (1) est un modèle d'autorégression de premier ordre.\n",
    "La méthode convient aux séries chronologiques univariées sans tendance ni composantes saisonnières.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR example\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = confirmed_cases.values\n",
    "size = int(len(data) * 0.66)\n",
    "train, test = data[0:size], data[size:len(data)]\n",
    "# fit model\n",
    "AR_model = AR(data)\n",
    "AR_model_fit = AR_model.fit()\n",
    "# make prediction\n",
    "yhat = AR_model_fit.predict(len(data), len(data))\n",
    "print(yhat)\n",
    "\n",
    "#model_fit.predict(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future predictions using Linear Regression \n",
    "print('Model AR future predictions:')\n",
    "set(zip(future_forcast_dates[23:23+7], np.round(AR_model_fit.predict(len(data),len(data)+6)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(10,5))\n",
    "plt.plot(future_forcast_dates[23:23+7], model_fit.predict(len(data),len(data)+6) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Average (MA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The moving average (MA) method models the next step in the sequence as a linear function of the residual errors from a mean process at prior time steps.\n",
    "A moving average model is different from calculating the moving average of the time series.\n",
    "The notation for the model involves specifying the order of the model q as a parameter to the MA function, e.g. MA(q). For example, MA(1) is a first-order moving average model.\n",
    "The method is suitable for univariate time series without trend and seasonal components\n",
    "\n",
    "La méthode de la moyenne mobile (MA) modélise la prochaine étape de la séquence en fonction linéaire des erreurs résiduelles d'un processus moyen à des pas de temps antérieurs.\n",
    "Un modèle de moyenne mobile est différent du calcul de la moyenne mobile de la série chronologique.\n",
    "La notation du modèle implique de spécifier l'ordre du modèle q en tant que paramètre de la fonction MA, par ex. MA (q). Par exemple, MA (1) est un modèle de moyenne mobile de premier ordre.\n",
    "La méthode convient aux séries chronologiques univariées sans tendance ni composantes saisonnières"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MA example\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from random import random\n",
    "# contrived dataset\n",
    "# fit model\n",
    "MA_model = ARMA(data, order=(0, 1))\n",
    "MA_model_fit = MA_model.fit(disp=False)\n",
    "# make prediction\n",
    "yhat = MA_model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future predictions using Linear Regression \n",
    "print('Model MA future predictions:')\n",
    "set(zip(future_forcast_dates[23:23+7], np.round(MA_model_fit.predict(len(data),len(data)+6)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive Moving Average (ARMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de la moyenne mobile autorégressive (ARMA) modélise la prochaine étape de la séquence en fonction linéaire des observations et des erreurs résiudales aux pas de temps précédents.\n",
    "\n",
    "Il combine à la fois les modèles d'autorégression (AR) et de moyenne mobile (MA).\n",
    "\n",
    "La notation du modèle implique de spécifier l'ordre des modèles AR (p) et MA (q) en tant que paramètres d'une fonction ARMA, par ex. ARMA (p, q). Un modèle ARIMA peut être utilisé pour développer des modèles AR ou MA.\n",
    "\n",
    "La méthode convient aux séries chronologiques univariées sans tendance ni composantes saisonnières"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARMA example\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from random import random\n",
    "# contrived dataset\n",
    "# fit model\n",
    "ARMA_model = ARMA(data, order=(2, 1))\n",
    "ARMA_model_fit = ARMA_model.fit(disp=False)\n",
    "# make prediction\n",
    "yhat = ARMA_model_fit.predict(len(data), len(data))\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future predictions using Linear Regression \n",
    "print('Model ARMA future predictions:')\n",
    "set(zip(future_forcast_dates[23:23+7], np.round(ARMA_model_fit.predict(len(data),len(data)+6)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Autoregressive Integrated Moving-Average (SARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode SARIMA (Seasonal Autoregressive Integrated Moving Average) modélise la prochaine étape de la séquence en fonction linéaire des observations différenciées, des erreurs, des observations saisonnières différenciées et des erreurs saisonnières aux pas de temps précédents.\n",
    "\n",
    "Il combine le modèle ARIMA avec la possibilité d'effectuer la même autorégression, différenciation et modélisation de la moyenne mobile au niveau saisonnier.\n",
    "\n",
    "La notation du modèle implique de spécifier l'ordre des modèles AR (p), I (d) et MA (q) comme paramètres d'une fonction ARIMA et AR (P), I (D), MA (Q) et m paramètres au niveau saisonnier, par exemple SARIMA (p, d, q) (P, D, Q) m où «m» est le nombre de pas de temps dans chaque saison (la période saisonnière). Un modèle SARIMA peut être utilisé pour développer des modèles AR, MA, ARMA et ARIMA.\n",
    "\n",
    "La méthode convient aux séries chronologiques univariées avec des composantes de tendance et / ou saisonnières.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMA example\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from random import random\n",
    "# contrived dataset\n",
    "#data = [x + random() for x in range(1, 100)]\n",
    "# fit model\n",
    "SARIMAX_model = SARIMAX(data, order=(1, 1, 1), seasonal_order=(1, 1, 1, 1))\n",
    "SARIMAX_model_fit = SARIMAX_model.fit(disp=False)\n",
    "# make prediction\n",
    "yhat = SARIMAX_model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future predictions using Linear Regression \n",
    "print('Model SARIMAX future predictions:')\n",
    "set(zip(future_forcast_dates[23:23+7], np.round(SARIMAX_model_fit.predict(len(data),len(data)+6)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate time Series Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Autoregression (VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAR example\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from random import random\n",
    "# contrived dataset with dependency\n",
    "data = pd.concat([confirmed_cases, total], axis=1)\n",
    "# fit model\n",
    "model = VAR(data)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.forecast(model_fit.y, steps=1)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predict = pd.DataFrame({\n",
    "                    'Date' : future_forcast_dates[-7:],\n",
    "                    'Bayesian': np.round(bayesian_pred[-7:]),\n",
    "                    'AR_model':np.round(AR_model_fit.predict(len(data),len(data)+6)),\n",
    "                    'MA_model': np.round(MA_model_fit.predict(len(data),len(data)+6)),\n",
    "                    'ARMA_model' : np.round(ARMA_model_fit.predict(len(data),len(data)+6)),\n",
    "                    'SARIMAX': np.round(SARIMAX_model_fit.predict(len(data),len(data)+6)), \n",
    "                    'Real_value': [6,14,11,12,0,0,0]\n",
    "\n",
    "\n",
    "})\n",
    "    \n",
    "base_predict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predict1 = pd.DataFrame({\n",
    "                    'Date' : future_forcast_dates[-9:],\n",
    "                    #'Model_1': np.round(bayesian_pred[-7:]),\n",
    "                    #'Com_Model_1': np.round(bayesian_pred[-7:]) - [6,14,11,12,20,13,0] ,\n",
    "    \n",
    "                    #'Model_2':np.round(AR_model_fit.predict(len(data),len(data)+6)),\n",
    "                    #'Com_Model_2' : np.round(AR_model_fit.predict(len(data),len(data)+6))- [6,14,11,12,20,13,0] ,\n",
    "                    \n",
    "                    #'Model_3': np.round(MA_model_fit.predict(len(data),len(data)+6)),\n",
    "                    #'Com_Model_3': np.round(MA_model_fit.predict(len(data),len(data)+6))- [6,14,11,12,0,0,0] ,\n",
    "    \n",
    "    \n",
    "                    #'Model_4' : np.round(ARMA_model_fit.predict(len(data),len(data)+6)),\n",
    "                    #'Com_Model_4': np.round(ARMA_model_fit.predict(len(data),len(data)+6))- [6,14,11,12,0,0,0] ,\n",
    "\n",
    "                    #'Model_5': np.round(SARIMAX_model_fit.predict(len(data),len(data)+6)), \n",
    "                    #'Com_Model_5': np.round(SARIMAX_model_fit.predict(len(data),len(data)+6))- [6,14,11,12,0,0,0] ,\n",
    "\n",
    "    \n",
    "                    #'Real_value': [6,14,11,12,20,13,0]\n",
    "\n",
    "\n",
    "})\n",
    "    \n",
    "base_predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "START_DATE = {\n",
    "    'Burkina Faso': '10/03/20',\n",
    "    'Benin': '16/03/20',\n",
    "    #'Cote Ivoire': '1/22/20',\n",
    "    'Cabo Verde': '20/03/20',\n",
    "    'Ghana' :  '14/03/20'   ,\n",
    "    'Gambia':'17/03/20'  ,\n",
    "    'Guinea':'13/03/20'  ,\n",
    "    'Guinea-Bissau': '25/03/20'  ,\n",
    "    'Liberia': '16/03/20'  ,\n",
    "    'Mali': '25/03/20'  ,\n",
    "    'Niger': '20/03/20'  ,\n",
    "    'Nigeria': '28/02/20'  ,\n",
    "    #'Sierra Leone':'20/03/20'  ,\n",
    "    'Senegal': '02/03/20'  ,\n",
    "    'Togo': '06/03/20'  ,\n",
    "}\n",
    "\n",
    "class Learner(object):\n",
    "    def __init__(self, country, loss):\n",
    "        self.country = country\n",
    "        self.loss = loss\n",
    "\n",
    "    def load_confirmed(self, country):\n",
    "      \"\"\"\n",
    "      Load confirmed cases downloaded from HDX\n",
    "      \"\"\"\n",
    "      df = pd.read_csv('dailycasenumber_oa.csv', sep =',')\n",
    "      country_df = df[df['Country/Region'] == country]\n",
    "      return country_df.iloc[0].loc[START_DATE[country]:]\n",
    "\n",
    "    def extend_index(self, index, new_size):\n",
    "        values = index.values\n",
    "        current = datetime.strptime(index[-1], '%m/%d/%y')\n",
    "        while len(values) < new_size:\n",
    "            current = current + timedelta(days=1)\n",
    "            values = np.append(values, datetime.strftime(current, '%m/%d/%y'))\n",
    "        return values\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, beta, gamma, data):\n",
    "        \"\"\"\n",
    "        Predict how the number of people in each compartment can be changed through time toward the future.\n",
    "        The model is formulated with the given beta and gamma.\n",
    "        \"\"\"\n",
    "        predict_range = 150\n",
    "        new_index = self.extend_index(data.index, predict_range)\n",
    "        size = len(new_index)\n",
    "        def SIR(t, y):\n",
    "            S = y[0]\n",
    "            I = y[1]\n",
    "            R = y[2]\n",
    "            return [-beta*S*I, beta*S*I-gamma*I, gamma*I]\n",
    "        extended_actual = np.concatenate((data.values, [None] * (size - len(data.values))))\n",
    "        return new_index, extended_actual, solve_ivp(SIR, [0, size], [S_0,I_0,R_0], t_eval=np.arange(0, size, 1))\n",
    "\n",
    "def train(self):\n",
    "        \"\"\"\n",
    "        Run the optimization to estimate the beta and gamma fitting the given confirmed cases.\n",
    "        \"\"\"\n",
    "        data = self.load_confirmed(self.country)\n",
    "        optimal = minimize(\n",
    "            loss,\n",
    "            [0.001, 0.001],\n",
    "            args=(data),\n",
    "            method='L-BFGS-B',\n",
    "            bounds=[(0.00000001, 0.4), (0.00000001, 0.4)]\n",
    "        )\n",
    "        beta, gamma = optimal.x\n",
    "        new_index, extended_actual, prediction = self.predict(beta, gamma, data)\n",
    "        df = pd.DataFrame({\n",
    "            'Actual': extended_actual,\n",
    "            'S': prediction.y[0],\n",
    "            'I': prediction.y[1],\n",
    "            'R': prediction.y[2]\n",
    "        }, index=new_index)\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))\n",
    "        ax.set_title(self.country)\n",
    "        df.plot(ax=ax)\n",
    "        fig.savefig(f\"{self.country}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(point, data):\n",
    "    \"\"\"\n",
    "    RMSE between actual confirmed cases and the estimated infectious people with given beta and gamma.\n",
    "    \"\"\"\n",
    "    size = len(data)\n",
    "    beta, gamma = point\n",
    "    def SIR(t, y):\n",
    "        S = y[0]\n",
    "        I = y[1]\n",
    "        R = y[2]\n",
    "        return [-beta*S*I, beta*S*I-gamma*I, gamma*I]\n",
    "    solution = solve_ivp(SIR, [0, size], [S_0,I_0,R_0], t_eval=np.arange(0, size, 1), vectorized=True)\n",
    "    return np.sqrt(np.mean((solution.y[1] - data)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(point, data, recovered):\n",
    "    size = len(data)\n",
    "    beta, gamma = point\n",
    "    def SIR(t, y):\n",
    "        S = y[0]\n",
    "        I = y[1]\n",
    "        R = y[2]\n",
    "        return [-beta*S*I, beta*S*I-gamma*I, gamma*I]\n",
    "    solution = solve_ivp(SIR, [0, size], [S_0,I_0,R_0], t_eval=np.arange(0, size, 1), vectorized=True)\n",
    "    l1 = np.sqrt(np.mean((solution.y[1] - data)**2))\n",
    "    l2 = np.sqrt(np.mean((solution.y[2] - recovered)**2))\n",
    "    # Put more emphasis on recovered people\n",
    "    alpha = 0.1\n",
    "    return alpha * l1 + (1 - alpha) * l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
