{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import random\n",
    "import math\n",
    "from scipy.stats import expon\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import datetime\n",
    "import operator \n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import scipy.optimize as optim\n",
    "\n",
    "#from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture et Preparation des donnees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons une modelisation des cas confirmes par jour et des cas confirmes cumulatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"https://raw.githubusercontent.com/maelfabien/COVID-19-Senegal/master/COVID_Dakar.csv\",sep=\";\" )\n",
    "#df.tail()\n",
    "#df = pd.read_csv(\"COVID_Senegal.csv\",sep=\";\" )\n",
    "#print(df.head())\n",
    "#confirmed_df = df[df['Positif']==1]\n",
    "#confirmed = confirmed_df[['Date', 'Positif']]\n",
    "#confirmed_cases= confirmed[['Date', 'Positif']].groupby(\"Date\").sum()\n",
    "\n",
    "#deaths_df = df[df['Décédé']==1]\n",
    "#deaths = deaths_df[['Date', 'Décédé']]\n",
    "#deaths_cases= deaths[['Date', 'Décédé']].groupby(\"Date\").sum()\n",
    "\n",
    "#recoveries_df = df[df['Guéri']==1]\n",
    "#recoveries = recoveries_df[['Date', 'Guéri']]\n",
    "#recoveries_cases= recoveries[['Date', 'Guéri']].groupby(\"Date\").sum()\n",
    "\n",
    "\n",
    "#negatif_df = df[df['Negatif']==1  ]\n",
    "#negatif = negatif_df[['Date', 'Negatif']]\n",
    "#negatif_cases=negatif[['Date', 'Negatif']].groupby(\"Date\").sum()\n",
    "\n",
    "\n",
    "#len(confirmed_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dailycasenumber_oa.csv\",sep=\",\")\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df['Country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_var(ct,df):\n",
    "    \n",
    "    \"\"\"\n",
    "      This function takes the countries name and database in parameters.\n",
    "      It returns a datframe with daily cases value and date as index\n",
    "    \"\"\"\n",
    "    #Prepare country data\n",
    "    ct_df = df[df['Country'] == ct]\n",
    "    first_date = ct_df[ct_df['Confirmed_cases'] != 0]['Date'].values[0]\n",
    "    confirmed = ct_df[ct_df['Date'] >= first_date]\n",
    "    confirmed_cases = confirmed[['Date', 'Daily_case']].set_index('Date')\n",
    "    \n",
    "    \n",
    "    return confirmed_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Preparation des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_data (conf):\n",
    "          \n",
    "    \"\"\"\n",
    "      This function takes the daily dataframe and return it as arrays value\n",
    "      for modelling purpose\n",
    "    \"\"\"\n",
    "    #rearange dataframe values in array format\n",
    "    cases_daily = np.array(conf).reshape(-1,1)\n",
    "    cases_cum = np.array(conf.cumsum()).reshape(-1,1)\n",
    "    days_since = np.arange(len(conf)).reshape(-1,1)\n",
    "    \n",
    "    return  cases_daily, cases_cum, days_since\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temps predictif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_date (n, conf):\n",
    "    \n",
    "    \"\"\"\n",
    "      This function generates n days for prediction\n",
    "    \"\"\"\n",
    "    future_forcast = np.arange(len(conf) + n).reshape(-1,1)\n",
    "    start_date = conf.index[0]\n",
    "    future_forcast_dates = [(start_date + datetime.timedelta(days=i)).strftime('%d/%m/%Y') for i in range(len(future_forcast))] \n",
    "    \n",
    "    return future_forcast,future_forcast_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la régression linéaire bayésien est une méthode de régression linéaire dans laquelle \n",
    "l'analyse statistique est réalisée dans le cadre de l'inférence bayésienne . \n",
    "Lorsque le modèle de régression a des erreurs qui ont une distribution normale , \n",
    "et si une forme particulière de la distribution préalable suppose, les résultats explicites sont disponibles\n",
    "pour les distributions de probabilité postérieure des paramètres du modèle.\n",
    "\n",
    "https://fr.qwe.wiki/wiki/Bayesian_linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_model(ct, df, n, mode = 'normal', plot = False):\n",
    "    \n",
    "    \"\"\"\n",
    "      This function defines init and run the bayesian model\n",
    "    \"\"\"\n",
    "     \n",
    "    cases_df = get_daily_var(ct,df)   \n",
    "    cases_daily, cases_cum, days_since = get_pred_data(cases_df)\n",
    "    future_forcast,future_forcast_dates = get_pred_date(n, cases_df)\n",
    "    \n",
    "    # bayesian ridge (Init and fit)\n",
    "    tol = [1e-4, 1e-3, 1e-2]\n",
    "    alpha_1 = [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "    alpha_2 = [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "    lambda_1 = [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "    lambda_2 = [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "\n",
    "    bayesian_grid = {'tol': tol, 'alpha_1': alpha_1, 'alpha_2' : alpha_2, 'lambda_1': lambda_1, 'lambda_2' : lambda_2}\n",
    "\n",
    "    bayesian = BayesianRidge(compute_score=True)\n",
    "    bayesian_search = RandomizedSearchCV(bayesian, bayesian_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=40, verbose=1)\n",
    "\n",
    "    if mode == 'normal':\n",
    "        cases = cases_daily\n",
    "        X_train_daily, X_test_daily, y_train_daily, y_test_daily = train_test_split(days_since, cases, test_size=0.25, shuffle=False)  \n",
    "        bayesian_search.fit(X_train_daily, y_train_daily)\n",
    "        bayesian_daily_params = bayesian_search.best_estimator_\n",
    "        bayesian_pred = bayesian_daily_params.predict(X_test_daily)\n",
    "        print('MAE:', mean_absolute_error(bayesian_pred, y_test_daily))\n",
    "        print('MSE:',mean_squared_error(bayesian_pred, y_test_daily))\n",
    "        bayesian_pred_future = bayesian_daily_params.predict(future_forcast)       \n",
    "       \n",
    "          \n",
    "    if mode == 'cum':\n",
    "        cases = cases_cum\n",
    "        X_train_cum, X_test_cum, y_train_cum, y_test_cum = train_test_split(days_since, cases, test_size=0.25, shuffle=False)  \n",
    "        bayesian_search.fit(X_train_cum, y_train_cum)\n",
    "        bayesian_cum_params = bayesian_search.best_estimator_\n",
    "        bayesian_pred = bayesian_cum_params.predict(X_test_cum)\n",
    "        print('MAE:', mean_absolute_error(bayesian_pred, y_test_cum))\n",
    "        print('MSE:',mean_squared_error(bayesian_pred, y_test_cum))\n",
    "        bayesian_pred_future = bayesian_cum_params.predict(future_forcast)       \n",
    "        \n",
    "        \n",
    "    if plot == True:\n",
    "        plt.figure(figsize=(20, 12))\n",
    "        plt.plot(future_forcast_dates[:-n], cases)\n",
    "        plt.plot(future_forcast_dates, bayesian_pred_future, linestyle='dashed', color='green')\n",
    "        plt.title(f'Nombre de cas confirmes au {ct} en fonction du temps', size=30)\n",
    "        plt.xlabel('Temps', size=30)\n",
    "        plt.ylabel('Nombre de cas', size=30)\n",
    "        plt.legend(['Cas Confirmes', 'Bayesian Ridge Regression Predictions'], prop={'size': 20})\n",
    "        plt.xticks(size=20, rotation= 90)\n",
    "        plt.yticks(size=20)\n",
    "        plt.show()            \n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_model('Senegal', df, n=5, mode = 'cum', plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def polynom_regression_model(ct, df, n=5, p=2, plot = False):\n",
    "    \"\"\"\n",
    "      This function defines init and run the polynomial regression model\n",
    "    \"\"\"\n",
    "    #Data prep\n",
    "    cases_df = get_daily_var(ct,df)   \n",
    "    _, cases_cum, days_since = get_pred_data(cases_df)\n",
    "    future_forcast,future_forcast_dates = get_pred_date(n, cases_df)\n",
    "    poly = PolynomialFeatures(degree = p)\n",
    "    \n",
    "    #Split Data\n",
    "    X_train_cum, X_test_cum, y_train_cum, y_test_cum = train_test_split(days_since, cases_cum, test_size=0.25, shuffle=False)\n",
    "    \n",
    "    #fit and init model                                                                   \n",
    "    X_poly = poly.fit_transform(X_train_cum)\n",
    "    poly.fit(X_poly, y_train_cum)\n",
    "    lin2 = LinearRegression()\n",
    "    lin2.fit(X_poly, y_train_cum)\n",
    "    cum_poly_pred_future = lin2.predict(poly.fit_transform(future_forcast))\n",
    "                                                                        \n",
    "    #ploting_results\n",
    "    if plot == True:\n",
    "                                                                        \n",
    "        plt.figure(figsize=(20, 12))\n",
    "        plt.plot(future_forcast_dates[:-n], cases_cum, color='blue')\n",
    "        plt.plot(future_forcast_dates, cum_poly_pred_future, linestyle='dashed', color='green')\n",
    "        plt.title(f'Nombre de cas confirmes au {ct} en fonction du temps', size=30)\n",
    "        plt.xlabel('Temps', size=20)\n",
    "        plt.ylabel('Nombre de cas', size=30)\n",
    "        plt.legend(['Cas Confirmes', 'polynomial Regression Predictions'], prop={'size': 30})\n",
    "        plt.xticks(size=20, rotation = 90)\n",
    "        plt.yticks(size=20)\n",
    "        plt.show() \n",
    "                                                                        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynom_regression_model('Senegal', df, n=5, p=2, plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Logistic Growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://jooskorstanje.com/modeling-logistic-growth-corona.html\n",
    "https://towardsdatascience.com/modeling-exponential-growth-49a2b6f22e1f\n",
    "https://towardsdatascience.com/modeling-exponential-growth-49a2b6f22e1f\n",
    "https://towardsdatascience.com/modeling-logistic-growth-1367dc971de2\n",
    "\n",
    "\n",
    "La croissance logistique est une fonction mathématique qui peut être utilisée dans plusieurs situations. La croissance logistique se caractérise par une croissance croissante au début, mais une croissance décroissante à un stade ultérieur, à mesure que l'on se rapproche d'un maximum. Par exemple, dans le cas du coronavirus, cette limite maximale serait le nombre total de personnes dans le monde, car lorsque tout le monde est malade, la croissance diminuera nécessairement.\n",
    "Dans d'autres cas d'utilisation de croissance logistique, ce nombre pourrait être la taille d'une population animale qui croît de façon exponentielle jusqu'au moment où leur environnement ne fournit pas suffisamment de nourriture pour tous les animaux et donc la croissance devient plus lente jusqu'à ce qu'une capacité maximale de l'environnement soit atteinte .\n",
    "La raison d'utiliser la croissance logistique pour modéliser l'épidémie de coronavirus est que les épidémiologistes ont étudié ces types d'épidémies et il est bien connu que la première période d'une épidémie suit la croissance exponentielle et que la période totale peut être modélisée avec une croissance logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_growth_model(ct, df, n=5, size = 3):\n",
    "    \n",
    "    cases_df = get_daily_var(ct,df)\n",
    "    future_forcast,future_forcast_dates = get_pred_date(n, cases_df)\n",
    "    \n",
    "    # Define funcion with the coefficients to estimate\n",
    "    def my_logistic(t, a, b, c):\n",
    "        return c / (1 + a * np.exp(-b*t))\n",
    "    \n",
    "    #Randomly initialize the coefficients\n",
    "    p0 = np.random.exponential(size=3)\n",
    "    \n",
    "    # Set min bound 0 on all coefficients, and set different max bounds for each coefficient\n",
    "    bounds = (0, [100, 3., 1000])\n",
    "    \n",
    "    # Convert pd.Series to np.Array and use Scipy's curve fit to find the best Nonlinear Least Squares coefficients\n",
    "    x = np.arange(len(cases_df)) + 1\n",
    "    y = np.array(cases_df.cumsum()['Daily_case'])\n",
    "    \n",
    "    (a,b,c),cov = optim.curve_fit(my_logistic, x, y, bounds=bounds, p0=p0)\n",
    "    \n",
    "    # Redefine the function with the new a, b and c\n",
    "    def my_logistic(t):\n",
    "        return c / (1 + a * np.exp(-b*t))\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.scatter(future_forcast_dates[0:len(y)], y)\n",
    "    plt.plot(x, my_logistic(x),color = 'red')\n",
    "    plt.title('Logistic Model vs Real Observations of Senegal Coronavirus')\n",
    "    plt.legend([ 'Logistic Model', 'Real data'])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Infections')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(future_forcast_dates, my_logistic(future_forcast),color = 'red')\n",
    "    plt.title(f'Logistic Model vs Real Observations of {ct} Coronavirus')\n",
    "    plt.legend([' Predict Logistic Model ', 'Real data'])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Infections')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "    \n",
    "    # The time step at which the growth is fastest\n",
    "    t_fastest = np.log(a) / b\n",
    "    t_fastest\n",
    "    print(np.round(t_fastest))\n",
    "    future_forcast_dates[27]\n",
    "    # First way to find the y of the fastest growth moment\n",
    "    y_fastest = c / 2\n",
    "    y_fastest\n",
    "    # Second way to find the y of the fastest growth moment\n",
    "    print(my_logistic(t_fastest))    \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_growth_model('Senegal', df, n=5, size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
